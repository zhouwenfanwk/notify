学习笔记：

接口：就是一个文件（js，json，php等）主要响应JSON数据或者xml数据。
{
	status: 1/0,
	msg: '提示信息'
}
-----
<xml>
	<status>1/0</status>
	<msg>提示信息</msg>
	...
</xml>
能够让项目静态/固定数据动态。（让项目数据来源于数据库）；一次编写，多次/随时接入。
一个文件，普遍返回json或者xml数据；1.让页面数据动态化；2，多功能：短信，人脸识别；自己写或者网站。

Restful API（响应不同来源的Http请求）

接口很多人开发，如何保证大家的编写规范相同。是一个架构思想，声明了接口的设计原则或约束条件。
接口测试工具：Postman&insomnia
----模拟HTTP请求，后端调试接口，前端看是否通，查看返回的数据字段。
express--基于node开发的框架。服务器逻辑以及接口。mongoose.js。
apiDoc按照文档自动生成在线接口文档。--swagger


api接口意味着预先定义一些函数，那个让应用程序或开发人员能具有访问指定网络资源的能力，而又无需关心自己访问的源码，或理解内部工作机制的细节。由一个地方统一的提供API接口使得多个平台来获取资源。（rest-表述性状态转移：客户端-服务器，无状态，可缓存，统一接口，分层系统，按需编码）

restful一切皆资源，用URI标识。表现指资源的表现，客户端和服务器间传递这种资源的某种表现层；

restful规范：
1.协议：api与用户的通信协议，总是使用http。
2.域名：将api部署在专用域名下。
3.版本：将api的版本号放入URL中。https://api.example.com/version;
4.路径：终点，标识api的具体网址。网址中不能有动词，只能有名词。数据库中的表都是同种记录的集合，所有名词应该用复数。
5.http动词：资源的具体操作，由http动词表示。常用的http动词有如下四个：--
6.过滤信息：记录数量很多，服务器不可能都将它们返回给用户。api提供参数，过滤返回结果。如：?limit=10;?offset=10;?page=2&per_page=100;
7.状态码：服务器向用户返回的状态码和提示信息，常见的有以下一些。200/201/202/400/401/404；
8.错误处理：如果产生错误，应该向用户返回出错的信息，一般来说，返回的信息中将error作为键名，出错信息作为键值即可。{error："invalid api key"}
9.返回结果：针对不同的操作，服务器向用户返回的结果应该符合：GET /collection:返回资源对象的列表；GET /collection/resources:返回单个资源对象；POST /collection:返回新生成的资源对象；PUT 返回完整资源对象；DELETE 返回空白文档。

MongoDB相关：

MongoDB是非关系型数据库，不同于mysql/DB2这些，它的灵活性较高，不适用sql意味着没有结构化的存储要求，没有约束。
不适用sql；水平可扩展；最终一致性（CAP）；高可扩展、分布式计算、低成本、半结构化。
它是基于分布式文件存储的，基于C++的为WEB应用提供可扩展的高性能数据存储解决方案。多用于数据采集和分散，大数据处理。
高可用和可增加服务器数量来对系统扩容。所有机器组成的子集集群将会比单台机器更加强大。
跨多个连接服务器对数据进行分区，也称为分片（横向扩展）。在下面情形下可以使用数据分片集群：
1.数据集大小很大且挑战单一系统容量；2.抓取的数据超过md内存；3.应用程序以写为主，跨多个服务器进行分散写操作，提高性能。
可以基于索引中的分片键的值来划分范围，或者依据哈希值来划分。

插件式存储引擎API为处理更多不同类型的业务提供了无限可能，内存存储引擎、事务存储引擎甚至HADOOP在未来都有可能介入。
MMAP缺陷：耗费磁盘空间和内存空间且难以清理，库级别锁，存储引擎消耗内存。mongo使用了第三方的WIredTiger存储引擎，它能够在文档级别实现并发控制，支持对磁盘数据进行压缩。数据的存储方式上：不像以往的将数据库中的所有集合和索引都混合存储在数据库文件中，导致占用的磁盘空间很难被回收，它会在集合和索引级别分配文件，集合以及索引都是单独的存储于文件，删除后，文件也会删除。WT会提供压缩算法，将硬盘数据缩小70%，索引缩小50%，提高IO性能。

反向代理：
1.反向代理（Reverse Proxy）方式是指用代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。
2.反向代理的典型用途是将防火墙后面的服务器提供给 Internet 用户访问，加强安全防护。反向代理还可以为后端的多台服务器提供负载均衡，或为后端较慢的服务器提供 缓冲 服务。另外，反向代理还可以启用高级 URL 策略和管理技术，从而使处于不同 web 服务器系统的 web 页面同时存在于同一个 URL 空间下。
这两个流程大致相同，但是起到的作用不一样。用户需要设置正向代理，反向代理是用户无法感知的，且通过一个统一的proxy去访问内部的服务器集群，以期实现服务器集群的负载均衡和动态分流。


mongoDB面试题：
1.MD成为最好的nosql因为-面向文件的 高性能 高可用性 易扩展性 丰富的查询语言。
2.Mongodb：文档数据库，提供好的性能，领先的非关系型数据库。采用BSON存储文档数据。
BSON（）是一种类json的一种二进制形式的存储格式，简称Binary JSON.
相对于json多了date类型和二进制数组。
3.对比RDBMS以及MONGODB：MySQL和MongoDB两者都是免费开源的数据库。MySQL和MongoDB有许多基本差别包括数据的表示(data representation)，查询，关系，事务，schema的设计和定义，标准化(normalization)，速度和性能。
通过比较MySQL和MongoDB，实际上我们是在比较关系型和非关系型数据库，即数据存储结构不同。


Hbase学习相关：

HBase 是一个构建在 Hadoop 文件系统之上的面向列的数据库管理系统。Hadoop 可以通过 HDFS 来存储结构化、半结构甚至非结构化的数据，它是传统数据库的补充，是海量数据存储的最佳方法，它针对大文件的存储，批量访问和流式访问都做了优化，同时也通过多副本解决了容灾问题。Hadoop 的缺陷在于它只能执行批处理，并且只能以顺序方式访问数据，新的方案来解决海量数据存储和随机访问的问题。行的一次读写操作时原子性的。
1.	特性：
不支持复杂的事务，只支持行级事务，即单行数据的读写都是原子性的；
由于是采用 HDFS 作为底层存储，所以和 HDFS 一样，支持结构化、半结构化和非结构化的存储；
支持通过增加机器进行横向扩展；
支持数据分片；
支持 RegionServers 之间的自动故障转移；
易于使用的 Java 客户端 API；
支持 BlockCache 和布隆过滤器；
过滤器支持谓词下推。
2.	Hbase 的表具有以下特点：
容量大：一个表可以有数十亿行，上百万列；
面向列：数据是按照列存储，每一列都单独存放，数据即索引，在查询时可以只访问指定列的数据，有效地降低了系统的 		I/O 负担；
稀疏性：空 (null) 列并不占用存储空间，表可以设计的非常稀疏 ；
数据多版本：每个单元中的数据可以有多个版本，按照时间戳排序，新的数据在最上面；
存储类型：所有数据的底层存储格式都是字节数组 (byte[])。
3.	Phoenix 是 HBase 的开源 SQL 中间层，它允许你使用标准 JDBC 的方式来操作 HBase 上的数据。在 Phoenix 之前，如果你要访问 HBase，只能调用它的 Java API，但相比于使用一行 SQL 就能实现数据查询，HBase 的 API 还是过于复杂。Phoenix 的理念是 we put sql SQL back in NOSQL，即你可以使用标准的 SQL 就能完成对 HBase 上数据的操作。Phoenix 的性能表现也非常优异.为小型数据查询提供毫秒级的性能，为千万行数据的查询提供秒级的性能。
4.	访问 HBase Table 中的数据，只有以下三种方式：
通过指定的 Row Key 进行访问；
通过 Row Key 的 range 进行访问，即访问指定范围内的行；
进行全表扫描。
5.	HBase Table 中的所有行按照 Row Key 的字典序排列。HBase Tables 通过行键的范围 (row key range) 被水平切分成多个 Region, 一个 Region 包含了在 start key 和 end key 之间的所有行。每个表一开始只有一个 Region，随着数据不断增加，Region 会不断增大，当增大到一个阀值的时候，Region 就会等分为两个新的 Region。当 Table 中的行不断增多，就会有越来越多的 Region。Region 是 HBase 中分布式存储和负载均衡的最小单元。这意味着不同的 Region 可以分布在不同的 Region Server 上。但一个 Region 是不会拆分到多个 Server 上的。
6.	Region Server 运行在 HDFS 的 DataNode 上。它具有以下组件：
WAL(Write Ahead Log，预写日志)：用于存储尚未进行持久化存储的数据记录，以便在发生故障时进行恢复。
BlockCache：读缓存。它将频繁读取的数据存储在内存中，如果存储不足，它将按照 最近最少使用原则 清除多余的数据。
MemStore：写缓存。它存储尚未写入磁盘的新数据，并会在数据写入磁盘之前对其进行排序。每个 Region 上的每个列族都有一个 MemStore。
HFile ：将行数据按照 Key\Values 的形式存储在文件系统上。
7.	Hbase系统架构：
Zookeeper
保证任何时候，集群中只有一个 Master；
存贮所有 Region 的寻址入口；
实时监控 Region Server 的状态，将 Region Server 的上线和下线信息实时通知给 Master；
存储 HBase 的 Schema，包括有哪些 Table，每个 Table 有哪些 Column Family 等信息。
Master
为 Region Server 分配 Region ；
负责 Region Server 的负载均衡 ；
发现失效的 Region Server 并重新分配其上的 Region；
GFS 上的垃圾文件回收；
处理 Schema 的更新请求。
Region Server
Region Server 负责维护 Master 分配给它的 Region ，并处理发送到 Region 上的 IO 请求；
Region Server 负责切分在运行过程中变得过大的 Region。
8.	组件间的协作：
-Zookeeper 负责维护可用服务列表，并提供服务故障通知等服务。
每个 Region Server 都会在 ZooKeeper 上创建一个临时节点，Master 通过 Zookeeper 的 Watcher 机制对节点进行监控，从而可以发现新加入的 Region Server 或故障退出的 Region Server；

-所有 Masters 会竞争性地在 Zookeeper 上创建同一个临时节点，由于 Zookeeper 只能有一个同名节点，所以必然只有一个 Master 能够创建成功，此时该 Master 就是主 Master，主 Master 会定期向 Zookeeper 发送心跳。备用 Masters 则通过 Watcher 机制对主 HMaster 所在节点进行监听；

-如果主 Master 未能定时发送心跳，则其持有的 Zookeeper 会话会过期，相应的临时节点也会被删除，这会触发定义在该节点上的 Watcher 事件，使得备用的 Master Servers 得到通知。所有备用的 Master Servers 在接到通知后，会再次去竞争性地创建临时节点，完成主 Master 的选举。
9.	写入数据的流程：
-Client 向 Region Server 提交写请求；
-Region Server 找到目标 Region；
-Region 检查数据是否与 Schema 一致；
-如果客户端没有指定版本，则获取当前系统时间作为数据版本；
-将更新写入 WAL Log；
-将更新写入 Memstore；
-判断 Memstore 存储是否已满，如果存储已满则需要 flush 为 Store Hfile 文件。
10.	读取数据的流程：
-客户端从 Zookeeper 获取 META 表所在的 Region Server；
-客户端访问 META 表所在的 Region Server，从 META 表中查询到访问行键所在的 Region Server，之后客户端将缓存这些信息以及 META 表的位置；
-客户端从行键所在的 Region Server 上获取数据。
11.	shell基本指令：
-create '表名称', '列族名称 1','列族名称 2','列名称 N'；
-create 'Student','baseInfo','schoolInfo'

-desc '表名'
-describe 'Student'

# 禁用表
disable 'Student'
# 检查表是否被禁用
is_disabled 'Student'
# 启用表
enable 'Student'
# 检查表是否被启用
is_enabled 'Student'

-exists 'Student'

# 删除表前需要先禁用表
disable 'Student'
# 删除表
drop 'Student'

添加列族
命令格式： alter '表名', '列族名'
alter 'Student', 'teacherInfo'

删除列族
命令格式：alter '表名', {NAME => '列族名', METHOD => 'delete'}
alter 'Student', {NAME => 'teacherInfo', METHOD => 'delete'}

put '表名', '行键','列族:列','值'
如果新增数据的行键值、列族名、列名与原有数据完全相同，则相当于更新操作

获取指定行、指定行中的列族、列的信息
# 获取指定行中所有列的数据信息
get 'Student','rowkey3'
# 获取指定行中指定列族下所有列的数据信息
get 'Student','rowkey3','baseInfo'
# 获取指定行中指定列的数据信息
get 'Student','rowkey3','baseInfo:name'

删除指定行、指定行中的列
# 删除指定行
delete 'Student','rowkey3'
# 删除指定行中指定列的数据
delete 'Student','rowkey3','baseInfo:name'
scan 'Student', {COLUMNS=> 'baseInfo:name',STARTROW => 'rowkey2',STOPROW => 'wrowkey4',LIMIT=>2, VERSIONS=>3}

Filter 可以设定一系列条件来进行过滤。
scan 'Student', FILTER=>"ValueFilter(=,'binary:24')"

12.	Hbase过滤器：
Hbase 提供了种类丰富的过滤器（filter）来提高数据处理的效率，用户可以通过内置或自定义的过滤器来对数据进行过滤，所有的过滤器都在服务端生效，即谓词下推（predicate push down）。这样可以保证过滤掉的数据不会被传送到客户端，从而减轻网络传输和客户端处理的压力。

Filter 接口中定义了过滤器的基本方法，FilterBase 抽象类实现了 Filter 接口。所有内置的过滤器则直接或者间接继承自 FilterBase 抽象类。用户只需要将定义好的过滤器通过 setFilter 方法传递给 Scan 或 put 的实例即可。


论文的问题：
- 作者主要参与完成了系统功能界面实现、数据的实时交互以及数据处理几个模块，到底为哪些模块？这是论文，不是项目报告，按照论文的思路来陈述工作，同时必须交代清楚其内涵和外延。
- 这是论文，不是你参与的项目，把所有与项目相关的内容，按照论文的模式重写！

- 形式化验证和定理验证是个很难的问题，问题复杂度为多少？如何验证有效性？

 测试部分结论与结果陈述不符。
- ，论文排版与规范不太相符，错别字较多，图表不清晰，参考文献需要进一步梳理，需认真修改以论文的方式撰写。

1，摘要部分格式需要根据规范调整。同时关键词需要跟论文主题相扣。
2，第1.2章第二段第一句语句不通，文中多处语句叙述问题，口语化严重。
3，第4.1.1和4.1.2章节中相关技术描述部分建议挪至第2章节关键技术部分加以介绍。
4，参考文献对齐根据规范调整。
对本学科、相关学科理论综述、总结。计量单位

评语：数据资料充分，论述过程严谨，思路清晰，结果可信。论文撰写严肃认真，推理符合逻辑，结论和建议具有现实意义，该论文反映出了作者在本门学科方面的理论基础，达到了专业硕士学位论文的要求，建议修改后安排答辩。


二审：
论文还存在如下不足：
1、综述部分的分析缺少文献支撑，研究目的不切实际；####
2、第2章的相关技术没有结合本项目的特点，较虚；##
3、设计部分缺少关键字段的数据设计；
4、部分参考文献缺乏学术性。###

1、摘要中未说明作者完成的几个模块是怎么完成的，描述其他技术没有意义；####
2、文献[1][3][11]等科普性的杂志不宜作为引文；##
3、图5-4、5中的数据定义在论文中没有出处；####
4、第5章流程图的分支标注不规范；####
5、测试过于简陋，内容笼统，非功能性测试无数值数据佐证；-------
6、参考文献的内容请仔细检查，按标准修改。##


周文帆同学的硕士毕业论文《基于Flask的形式化验证系统的设计与实现》在相关文献研究和时事动态分析的基础上，研究了形式化验证系统工具的设计与实现。其选题有一定的理论价值和现实意义。该论文在形式化技术兴起的背景下，开发出了一款具有自主知识产权的形式化验证工具。论文实现了一种更加简便的验证方案，基于Web系统实现了高阶逻辑定理以及计算机程序的验证工作，使用此验证工具时用户只需要接入互联网，并基于点击就可以进行验证工作，免去了复杂的编程式验证过程，验证过程速度更快且系统易用性强。论文采用规范分析和实证分析等方法来论证自己的观点，研究方法较为科学。论文创新之处：一是从新的角度来实现形式化验证过程；二是作为国内的自主创新技术来设计实现。论文有一定的理论深度。论文观点鲜明，论证清晰有力，论据充分可靠，数据准确，资料详实。文献综述丰富而规范。不足之处在于界面设计可以更加丰富，未来可以考虑加入人工智能算法来优化使其更加智能化。论文结构严谨，层次分明，采用了递进式的分析结构，逻辑性强，文笔流畅，表达清晰，重点突出，格式符合要求。反映作者有较强的独立科研能力。论文表明了作者掌握了软件工程学科的基本理论以及分析方法，论文达到了硕士学位论文水平，同意其参加论文答辩，并建议授予硕士学位。
